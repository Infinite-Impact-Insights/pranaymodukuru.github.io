<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Optimization | Pranay Modukuru</title>
    <link>https://pranaymodukuru.github.io/tags/optimization/</link>
      <atom:link href="https://pranaymodukuru.github.io/tags/optimization/index.xml" rel="self" type="application/rss+xml" />
    <description>Optimization</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Â© Pranay Modukuru 2020</copyright><lastBuildDate>Thu, 05 Mar 2020 01:53:52 +0100</lastBuildDate>
    <image>
      <url>https://pranaymodukuru.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Optimization</title>
      <link>https://pranaymodukuru.github.io/tags/optimization/</link>
    </image>
    
    <item>
      <title>Effect of Initialization on Optimization Trajectory in 2D</title>
      <link>https://pranaymodukuru.github.io/post/optimization-trajectory/</link>
      <pubDate>Thu, 05 Mar 2020 01:53:52 +0100</pubDate>
      <guid>https://pranaymodukuru.github.io/post/optimization-trajectory/</guid>
      <description>&lt;h3 id=&#34;the-optimization-problem&#34;&gt;The Optimization Problem&lt;/h3&gt;
&lt;p&gt;In simple words, finding a minimum value for a given equation is considered as optimization. This has many applications in real life - finding the fastest path when traveling from one place to other, job shop scheduling, air traffic management etc,. The optimization has been the back bone of machine learning, where the algorithms are expected to extract knowledge from huge volumes of data.&lt;/p&gt;
&lt;p&gt;Optimization plays a major role Neural Networks where there are millions of parameters and the goal is to find the right set of parameters to correctly represent the data. There has been a lot of research in this field and many algorithms have been developed for effective optimization. Even though the performance of the optimizer has improved a lot, there is another problem that the optimization depends upon i.e. the initial point. The trajectory of optimization is largely dependant on the initialisation. This has been studied and numerous initialization techniques have been proposed to effectively exploit the power of optimization algorithms.&lt;/p&gt;
&lt;p&gt;In this post we are going to see how the initialization can affect the performance of some of the optimization algorithms until day. Although, we are using a two dimensional problem here since it is easy to visualize, the initialization problem becomes more prevalent when there are millions of parameters (Neural Networks).&lt;/p&gt;
&lt;h3 id=&#34;the-task&#34;&gt;The Task&lt;/h3&gt;
&lt;p&gt;Initialize x, y and use gradient descent algorithms to find the optimal values of x and y such that the value of the Beale function is zero (or as low as possible).&lt;/p&gt;
&lt;h3 id=&#34;a-brief-introduction-to-optimization-algorithms&#34;&gt;A brief introduction to optimization algorithms&lt;/h3&gt;
&lt;p&gt;We are going to consider three popular optimization algorithms, since we are more concerned about the initialization these will be sufficient for our analysis.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Stochastic Gradient Descent&lt;/strong&gt; - The stochastic gradient descent (SGD) algorithm performs one update at a time computing gradients at each step.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Momentum&lt;/strong&gt; - Overcomes the difficulty of slow updates of stochastic gradient descent by considering the momentum of gradients over a period of time.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Adam&lt;/strong&gt; - Considered to be the most popular optimization algorithm. It takes into consideration the first and second moments i.e. the exponentially decaying average of past gradients and squared gradients.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;A more detailed explanation about gradient descent optimization algorithms, please read this 
&lt;a href=&#34;https://ruder.io/optimizing-gradient-descent/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;post&lt;/a&gt; by 
&lt;a href=&#34;https://ruder.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sebastian Ruder&lt;/a&gt;.&lt;/p&gt;
&lt;h6 id=&#34;importing-required-libraries&#34;&gt;Importing required libraries&lt;/h6&gt;
&lt;p&gt;We are going to use the autograd functionality of 
&lt;a href=&#34;https://pytorch.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PyTorch&lt;/a&gt; for getting the gradients and matplotlib for plotting the trajectories.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-Python&#34;&gt;import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from mpl_toolkits.mplot3d import Axes3D
from matplotlib.colors import LogNorm

import warnings
warnings.filterwarnings(&amp;quot;ignore&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;the-beale-function&#34;&gt;The Beale Function&lt;/h3&gt;
&lt;p&gt;$$
f(x, y) =  (1.5 - x + xy)^2 + (2.25 - x + xy^2)^2 +(2.625 - x + xy^3)^2\tag{1}
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Beale function is a multimodal non-convex continuous function defined in two dimensions.&lt;/li&gt;
&lt;li&gt;It is usually evaluated in the range $(x, y) \in [-4.5, 4.5]$.&lt;/li&gt;
&lt;li&gt;The function has only one global minimum at $(x, y) = (3, 0.5)$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The 
&lt;a href=&#34;https://www.sfu.ca/~ssurjano/beale.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Beale&lt;/a&gt; Function, a two dimentional function is chosen to make visualizations simple.&lt;/p&gt;
&lt;h6 id=&#34;visualizing-the-beale-function&#34;&gt;Visualizing the Beale Function&lt;/h6&gt;
&lt;p&gt;As the Beale function is a two variable function ranging between -4.5 and 4.5, we can generate a meshgrid using numpy to pass all the possible values of x and y to the function. This enables us to have the output of the beale&amp;rsquo;s function at each possible point, we can use these outputs to visualize the function in a contour plot.&lt;/p&gt;
&lt;p&gt;As we are relating the optimization problem with neural networks, we will refer to &lt;strong&gt;(x, y)&lt;/strong&gt; as &lt;strong&gt;(w1 , w2)&lt;/strong&gt;. Also, when using a neural network we refer to objective function as a loss function and the output of the function as loss. In this case, we refer to the Beale&amp;rsquo;s function as &lt;strong&gt;loss function&lt;/strong&gt; and the outputs as &lt;strong&gt;losses&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Defining function
f  = lambda x, y: (1.5 - x + x*y)**2 + (2.25 - x + x*y**2)**2 + (2.625 - x + x*y**3)**2

# Defining the range of w1 and w2, step size
w1_min, w1_max, w1_step = -4.5, 4.5, .2
w2_min, w2_max, w2_step = -4.5, 4.5, .2

# Global minima of the function
minima_ = [3, 0.5]

# generating meshgrid
w1, w2 = np.meshgrid(np.arange(w1_min, w1_max + w1_step, w1_step),
                     np.arange(w2_min, w2_max + w2_step, w2_step))
losses = f(w1, w2)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will now plot the losses on a contour plot with the following code.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fig, ax = plt.subplots(figsize=(10, 6))
ax.contour(w1, w2, losses, levels=np.logspace(0, 5, 35),
                    norm=LogNorm(), cmap=plt.cm.jet, alpha = 0.8)
ax.plot(*minima_, &#39;r*&#39;, color=&#39;r&#39;,
                    markersize=10, alpha=0.7, label=&#39;minima&#39;)
ax.set_xlabel(&#39;w1&#39;)
ax.set_ylabel(&#39;w2&#39;)
ax.set_xlim((w1_min, w1_max))
ax.set_ylim((w2_min, w2_max))
ax.legend(bbox_to_anchor=(1.2, 1.))
ax.set_title(&amp;quot;Beale Function&amp;quot;)
fig.tight_layout(rect=[0, 0.03, 1, 0.95])
&lt;/code&gt;&lt;/pre&gt;
&lt;h6 id=&#34;output&#34;&gt;Output&lt;/h6&gt;
&lt;p&gt;As seen in the image, blue region indicates lower values and the red region is higher values of the Beale&amp;rsquo;s function. The minima (3, 0.5) is indicated with a star.&lt;/p&gt;





  











&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://pranaymodukuru.github.io/img/optimization-trajectory-visualization/beale_func.png&#34; &gt;


  &lt;img src=&#34;https://pranaymodukuru.github.io/img/optimization-trajectory-visualization/beale_func.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h6 id=&#34;setting-up-parameters&#34;&gt;Setting up Parameters&lt;/h6&gt;
&lt;p&gt;As we are using PyTorch, we need to have parameters that are to be optimized put into a &lt;code&gt;nn.Module&lt;/code&gt; class. The &lt;code&gt;__init__()&lt;/code&gt; takes (x, y) as inputs to initialize the parameters (w1, w2).  Also, we are going to write the beale&amp;rsquo;s equation in the forward function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class Net_Beale(torch.nn.Module):
    def __init__(self, x, y):
        super(Net_Beale, self).__init__()
        self.w1 = torch.nn.Parameter(torch.tensor([x]))
        self.w2 = torch.nn.Parameter(torch.tensor([y]))

    def forward(self):
        # Beale Function Equation
        a = (1.5 - self.w1 + self.w1*self.w2)**2
        b = (2.25 - self.w1 + self.w1*self.w2**2)**2
        c = (2.625 - self.w1 + self.w1*self.w2**3)**2
        return a+b+c
&lt;/code&gt;&lt;/pre&gt;
&lt;h6 id=&#34;optimizing-and-saving-trajectory&#34;&gt;Optimizing and Saving Trajectory&lt;/h6&gt;
&lt;p&gt;Since we are interested in tracking the path of the optimization, we need to collect the parameters at each step/desired steps and save them for plotting.&lt;/p&gt;
&lt;p&gt;The below function initialises the parameters of the network, initializes an optimizer and runs the optimization for the specified number of steps while collecting the path of the parameters.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def get_trajectory(x, y, optim, lr, epochs, interval=1):

    # Initialize Network
    net = Net_Beale(x,y)

    # Initialize Optimizer
    if optim == &amp;quot;sgd&amp;quot;:
        optim = torch.optim.SGD(net.parameters(), lr)
    elif optim == &amp;quot;mom&amp;quot;:
        optim = torch.optim.SGD(net.parameters(), lr, momentum=0.9)
    elif optim == &amp;quot;adam&amp;quot;:
        optim = torch.optim.Adam(net.parameters(), lr)

    # Initialize Trackers
    w_1s = []
    w_2s = []

    # Run Optimization
    for i in range(epochs):
        optim.zero_grad()
        o = net()
        o.backward()

        if i % interval == 0:
            # Append current w1 and w2 to trackers
            w_1s.append(net.w1.item())
            w_2s.append(net.w2.item())
        optim.step()

    w_1s.append(net.w1.item())
    w_2s.append(net.w2.item())

    # Join w1&#39;s and w2&#39;s into one array
    trajectory = np.array([w_1s, w_2s])   

    return trajectory
&lt;/code&gt;&lt;/pre&gt;
&lt;h6 id=&#34;comparison-between-trajectories&#34;&gt;Comparison between trajectories&lt;/h6&gt;
&lt;p&gt;After collecting the paths of parameters with different algorithms, we are going to plot them on the Beale Function Contour plot. The below function takes in the initial position, list of optimizers and corresponding learning rates and epochs and plots the trajectories of algorithms with specified settings.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def compare_trajectories(x, y, epochs, optims, lrs):

    colors = [&#39;k&#39;, &#39;g&#39;, &#39;b&#39;, &#39;r&#39;, &#39;y&#39;, &#39;c&#39;, &#39;m&#39;]
    trajectories = []
    names = []
    # Loop on all optimizers in list
    for ep, optim, lr in zip(epochs, optims, lrs):
        trajectory = get_trajectory(float(x), float(y), optim=optim, lr=lr, epochs=ep)
        names.append(optim)
        trajectories.append(trajectory)

    # Plot the Contour plot of Beale Function and trajectories of optimizers
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.contour(w1, w2, losses, levels=np.logspace(0, 5, 35),
                        norm=LogNorm(), cmap=plt.cm.jet, alpha = 0.5)

    for i, trajectory in enumerate(trajectories):
        ax.quiver(trajectory[0,:-1], trajectory[1,:-1], trajectory[0,1:]-trajectory[0,:-1],
                  trajectory[1,1:]-trajectory[1,:-1], scale_units=&#39;xy&#39;, angles=&#39;xy&#39;, scale=1,
                  color=colors[i], label=names[i], alpha=0.8)

    start_ =[x,y]
    ax.plot(*start_, &#39;r*&#39;, color=&#39;k&#39;,markersize=10, alpha=0.7, label=&#39;start&#39;)
    ax.plot(*minima_, &#39;r*&#39;, color=&#39;r&#39;,markersize=10, alpha=0.7, label=&#39;minima&#39;)
    ax.set_xlabel(&#39;w1&#39;)
    ax.set_ylabel(&#39;w2&#39;)
    ax.set_xlim((w1_min, w1_max))
    ax.set_ylim((w2_min, w2_max))
    ax.set_title(&amp;quot;Initial point - ({},{})&amp;quot;.format(x,y))
    ax.legend(bbox_to_anchor=(1.2, 1.))
    fig.suptitle(&amp;quot;Optimization Trajectory&amp;quot;)
    fig.tight_layout(rect=[0, 0.03, 1, 0.95])
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;trying-different-initial-points&#34;&gt;Trying Different Initial Points&lt;/h3&gt;
&lt;p&gt;After setting up everything, we are now ready to compare the three algorithms with different initial points.&lt;/p&gt;
&lt;p&gt;The learning rates observed to be working in this problem&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SGD      - 0.0001&lt;/li&gt;
&lt;li&gt;momentum - 0.0001&lt;/li&gt;
&lt;li&gt;Adam     - 0.01&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We are going to use the same learning rate for different initial points considered for respective algorithms to keep the analysis simple and since we are not doing hyperparameter tuning. Feel free to download this 
&lt;a href=&#34;https://github.com/pranaymodukuru/OptimizationTrajectoryPlots/blob/master/OptimizationTrajectory_Initialization.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;notebook&lt;/a&gt; and trying out different hyperparameters and initial points.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Settings for optimizers
epochs = [10000] * 3
optims = [&#39;sgd&#39;, &#39;mom&#39;, &#39;adam&#39;]
lrs = [0.0001, 0.0001, 0.01]
&lt;/code&gt;&lt;/pre&gt;
&lt;h6 id=&#34;case-1--a-point-close-to-minima&#34;&gt;Case 1 : A point close to minima&lt;/h6&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#  A point closer to minima
x = 2.5
y = 2.
compare_trajectories(x, y, epochs, optims, lrs)
&lt;/code&gt;&lt;/pre&gt;





  











&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://pranaymodukuru.github.io/img/optimization-trajectory-visualization/close_to_minima.png&#34; &gt;


  &lt;img src=&#34;https://pranaymodukuru.github.io/img/optimization-trajectory-visualization/close_to_minima.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;All the three reach the global minima, lets move a little further and see what happens.&lt;/p&gt;
&lt;h6 id=&#34;case-2--moving-a-little-further&#34;&gt;Case 2 : Moving a little further&lt;/h6&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# A little away in the same region
x = 1.5
y = 2.5
compare_trajectories(x, y, epochs, optims, lrs)
&lt;/code&gt;&lt;/pre&gt;





  











&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://pranaymodukuru.github.io/img/optimization-trajectory-visualization/a_little_further.png&#34; &gt;


  &lt;img src=&#34;https://pranaymodukuru.github.io/img/optimization-trajectory-visualization/a_little_further.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;Moving a little further from where we have started has made a huge difference on how an optimizer moves the parameters towards minimum. As seen in the figure above &lt;strong&gt;adam&lt;/strong&gt; optimizer moves towards a local minimum and is stuck there, whereas &lt;strong&gt;sgd&lt;/strong&gt; and &lt;strong&gt;momentum&lt;/strong&gt; reach the global minimum. Things to notice, we are not changing the learning rate here, as we are focusing on effect of initialization on optimization.&lt;/p&gt;
&lt;h6 id=&#34;case-3--moving-a-little-further&#34;&gt;Case 3 : Moving a little further&lt;/h6&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Lower left region
x = -4
y = -4
compare_trajectories(x, y, epochs, optims, lrs)
&lt;/code&gt;&lt;/pre&gt;





  











&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://pranaymodukuru.github.io/img/optimization-trajectory-visualization/lower_left.png&#34; &gt;


  &lt;img src=&#34;https://pranaymodukuru.github.io/img/optimization-trajectory-visualization/lower_left.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;(more example can be found in this 
&lt;a href=&#34;https://github.com/pranaymodukuru/OptimizationTrajectoryPlots/blob/master/OptimizationTrajectory_Initialization.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;notebook&lt;/a&gt;)&lt;/p&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;The initial point plays a crucial role in optimization problems. Here we are trying to solve a two dimensional problem which is fairly easy when compared to finding a minima when we have a large dataset and more than million parameters (dimensions).&lt;/p&gt;
&lt;p&gt;Although we are not tuning the hyperparameters here, we can effectively drive the optimization in right direction with the right set of hyperparameters.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://mitpress.mit.edu/books/optimization-machine-learning&#34;&gt;https://mitpress.mit.edu/books/optimization-machine-learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Test_functions_for_optimization&#34;&gt;https://en.wikipedia.org/wiki/Test_functions_for_optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://benchmarkfcns.xyz/benchmarkfcns/bealefcn.html&#34;&gt;http://benchmarkfcns.xyz/benchmarkfcns/bealefcn.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ruder.io/optimizing-gradient-descent/&#34;&gt;https://ruder.io/optimizing-gradient-descent/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://louistiao.me/notes/visualizing-and-animating-optimization-algorithms-with-matplotlib/&#34;&gt;http://louistiao.me/notes/visualizing-and-animating-optimization-algorithms-with-matplotlib/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://communities.sas.com/t5/SAS-Communities-Library/Mathematical-Optimization-in-our-Daily-Lives/ta-p/504724#&#34;&gt;https://communities.sas.com/t5/SAS-Communities-Library/Mathematical-Optimization-in-our-Daily-Lives/ta-p/504724#&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
  </channel>
</rss>
